{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9486c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from typing import Any, Dict, List, Iterator, Optional, Tuple\n",
    "import torch\n",
    "import pytest\n",
    "import pretrainedmodels as pm\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28069ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'imagenet': {'url': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth', 'input_space': 'RGB', 'input_size': [3, 224, 224], 'input_range': [0, 1], 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'num_classes': 1000}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (_features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dropout0): Dropout(p=0.5, inplace=False)\n",
       "  (linear0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (relu0): ReLU(inplace=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (linear1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (last_linear): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aqui é chamada a Rede Neural\n",
    "print(pretrainedmodels.pretrained_settings['alexnet'])\n",
    "model_name = 'alexnet'\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "359ce9a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-666c619a7b50>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-666c619a7b50>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    [docs]class ImageNet(ImageFolder):\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ARCHIVE_META = {\n",
    "    'train': ('ILSVRC2012_img_train.tar', '1d675b47d978889d74fa0da5fadfb00e'),\n",
    "    'val': ('ILSVRC2012_img_val.tar', '29b22e2961454d5413ddabcf34fc5622')}\n",
    "\n",
    "META_FILE = \"meta.bin\"\n",
    "\n",
    "[docs]class ImageNet(ImageFolder):\n",
    "    \"\"\"`ImageNet <http://image-net.org/>`_ 2012 Classification Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4303bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de validação\n",
    "def validate(model, test_dataloader):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    for int, data in enumerate(test_dataloader):\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        val_running_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        val_running_correct += (preds == target).sum().item()\n",
    "    \n",
    "    val_loss = val_running_loss/len(test_dataloader.dataset)\n",
    "    val_accuracy = 100. * val_running_correct/len(test_dataloader.dataset)\n",
    "    \n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02104d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de treino\n",
    "def fit(model, train_dataloader):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_running_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        train_running_correct += (preds == target).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss = train_running_loss/len(train_dataloader.dataset)\n",
    "    train_accuracy = 100. * train_running_correct/len(train_dataloader.dataset)\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}')\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado de treino e validação\n",
    "train_loss , train_accuracy = [], []\n",
    "val_loss , val_accuracy = [], []\n",
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    train_epoch_loss, train_epoch_accuracy = fit(vgg16, trainloader)\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(vgg16, testloader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
